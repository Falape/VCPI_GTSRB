{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho prático - Visão por Computador e Processamento de Imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autores: Cláudio Moreira (PG47844), Filipe Fernandes(A83996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o presente trabalho foi proposta a exploração de modelos de *Deep Learning*. Numa primeira parte, é suposto treinar modelos aplicando *data augmentation*, tanto em pré-processamento como dinâmico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste *notebook* abordou-se os processos de alteração de imagens de forma massiva. Para isso utilizou-se as funções de processamento descritas posteriormente de modo a alterar o brilho, contraste, saturação, hue, rotação, rotação, translação e redimensionar as imagens. Começou-se por importar os seguintes modulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "# to display confusion matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Avasilable: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massive data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [WIDTH, HEIGHT])\n",
    "\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "def show_batch(image_batch, label_batch, epoch):\n",
    "  columns = 5\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  epochImages = plt.figure(figsize=(15, 3 * rows))\n",
    "  epochImages.suptitle('epoch {}'.format(epoch))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(int(rows), columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    "\n",
    "def show_batchSimple(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(int(rows), columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_callbacks(file_path):\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                               monitor = 'val_accuracy',\n",
    "                               verbose=1, \n",
    "                               save_weights_only=True,\n",
    "                               save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001, patience = 15, verbose = 1)\n",
    "\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
    "\n",
    "    return [checkpointer, earlyStopper, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "def show_accuracies(): \n",
    "    fig, ax = plt.subplots()\n",
    "    X = np.arange(2)\n",
    "\n",
    "    models = ['bad val set', 'good val set']\n",
    "    plt.bar(X, [evalV1[1], evalV2[1]], width = 0.4, color = 'b', label='test')\n",
    "    plt.bar(X + 0.4, [valV1[1], valV2[1]], color = 'r', width = 0.4, label = \"val\")\n",
    "    plt.xticks(X + 0.4 / 2, models)\n",
    "    plt.ylim(top = 1.0, bottom = 0.80)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_misclassified(predictions, ground_truth, images, num_rows= 5, num_cols=3):\n",
    "    \n",
    "    # Plot the first X test images with wrong predictions.\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while k < len(images) and i < num_images:\n",
    "        predicted_label = np.argmax(predictions[k])\n",
    "        gt = np.where(ground_truth[k])[0][0]\n",
    "        if predicted_label != gt:\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "            plot_image(k, predictions[k], gt, images)\n",
    "            plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "            plot_value_array(k, predictions[k], ground_truth)\n",
    "            i += 1\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label, img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(classNames[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                classNames[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(8))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[np.where(true_label)[0][0]].set_color('blue')    \n",
    "\n",
    "def plot_predictions(predictions, ground_truth, images, num_rows= 5, num_cols=3 ):\n",
    "\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "    for i in range(min(num_images,len(images))):\n",
    "        gt = np.where(ground_truth[i])[0][0]\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions[i], gt, images)\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(i, predictions[i], ground_truth)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTrain = 'GTSRB_TP/train_images'\n",
    "pathTest = 'GTSRB_TP/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "#Classes names\n",
    "data_dir = pathlib.Path(pathTrain)\n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(pathTrain+\"/*/*.png\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = next(iter(dataset))\n",
    "print(t[0].shape, t[1].shape)\n",
    "#print(dataset)\n",
    "# note: this only works if dataset is not repeating\n",
    "train_Data_length = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(\"Total images in dataset: \", train_Data_length)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicação da aleatoriedade no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size = train_Data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#não está funcionar porque são faço batches no dataset\n",
    "# image_batch, label_batch = next(iter(dataset))        \n",
    "# show_batchSimple(image_batch, label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listset = tf.data.Dataset.list_files(pathTest+\"/*/*.png\")\n",
    "test_Data = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Data_length = tf.data.experimental.cardinality(test_Data).numpy()\n",
    "print(\"Total images in dataset: \", test_Data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Data = test_Data.batch(batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento da Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def process_brightness(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_saturation(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
    "    return img, label\n",
    "\n",
    "def process_contrast(image, label):\n",
    "    \n",
    "    img = tf.clip_by_value(tf.image.random_contrast(image, lower=0.1, upper=3.0, seed=None), 0, 1)\n",
    "    return img, label\n",
    "\n",
    "def process_hue(image, label):\n",
    "    \n",
    "    img = tf.image.random_hue(image, max_delta=0.2, seed=None)\n",
    "    return img, label\n",
    "\n",
    "def process_rotate(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    return img, label\n",
    "\n",
    "def process_shear(image, label):\n",
    "    \n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
    "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
    "    return img, label\n",
    "\n",
    "def process_translate(image, label):\n",
    "\n",
    "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
    "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
    "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
    "    img = tfa.image.translate(img, [tx,ty])\n",
    "    return img, label\n",
    "\n",
    "def process_crop(image, label):\n",
    "    \n",
    "    c = tf.random.uniform(shape=(), minval=24, maxval=32, dtype=tf.dtypes.float32)\n",
    "    img = tf.image.random_crop(image, size=[c,c,3])\n",
    "    img = tf.image.resize(img ,size= [32,32])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset\n",
    "# color ops\n",
    "train_dataset = train_dataset.map(process_brightness)\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_contrast))\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_hue))\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_saturation))\n",
    "\n",
    "#geometry ops\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_rotate))\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_shear))\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_translate))\n",
    "train_dataset = train_dataset.concatenate(dataset.map(process_crop))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_length = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "print(\"Total images in dataset: \", train_dataset_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size = train_dataset_length)\n",
    "train_dataset = train_dataset.batch(batch_size = BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver os batchs\n",
    "image_batch, label_batch = next(iter(train_dataset))        \n",
    "show_batch(image_batch, label_batch.numpy(), 1)\n",
    "image_batch, label_batch = next(iter(train_dataset))      \n",
    "show_batch(image_batch, label_batch.numpy(), 2)\n",
    "image_batch, label_batch = next(iter(train_dataset))      \n",
    "show_batch(image_batch, label_batch.numpy(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*train_dataset_length)\n",
    "val_size = int(0.2*train_dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Data = train_dataset.take(train_size)\n",
    "val_Data = train_dataset.skip(train_size)\n",
    "print(tf.data.experimental.cardinality(train_Data).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelV3 = Sequential()\n",
    "\n",
    "modelV3.add(Conv2D(128, (5, 5),\n",
    "                    input_shape=(32, 32, 3)))         \n",
    "modelV3.add(LeakyReLU(alpha=0.01))  \n",
    "modelV3.add(BatchNormalization())\n",
    "modelV3.add(Dropout(0.5)) \n",
    "\n",
    "modelV3.add(Conv2D(196, (5, 5) )) \n",
    "modelV3.add(LeakyReLU(alpha=0.01))\n",
    "modelV3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelV3.add(BatchNormalization())\n",
    "modelV3.add(Dropout(0.5)) \n",
    "\n",
    "modelV3.add(Conv2D(256, (5, 5) ) )   \n",
    "modelV3.add(LeakyReLU(alpha=0.01))\n",
    "modelV3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelV3.add(BatchNormalization())\n",
    "modelV3.add(Dropout(0.5)) \n",
    "\n",
    "modelV3.add(Flatten())\n",
    "modelV3.add(LeakyReLU(alpha=0.0)) \n",
    "modelV3.add(Dense(384))\n",
    "modelV3.add(LeakyReLU(alpha=0.0))             \n",
    "modelV3.add(Dropout(0.5)) \n",
    "\n",
    "modelV3.add(Dense(43, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "modelV3.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pathV3 = './TrainModels/Massive_Augmentation.ckpt'\n",
    "\n",
    "callbacksV3 = prepare_callbacks(file_pathV3)\n",
    "\n",
    "historyV3 = modelV3.fit(train_Data, steps_per_epoch = train_size/BATCH_SIZE,\n",
    "          epochs=50, \n",
    "          validation_data = val_Data,\n",
    "          validation_steps=val_size/BATCH_SIZE, \n",
    "          callbacks = callbacksV3)\n",
    "\n",
    "# historyV3 = modelV3.fit(dataV3,\n",
    "#           epochs=50, \n",
    "#           validation_data = val_Data, \n",
    "#           callbacks = callbacksV3)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(historyV3)\n",
    "\n",
    "modelV3.load_weights(file_pathV3)\n",
    "\n",
    "evalV3 = modelV3.evaluate(test_Data, verbose=2)\n",
    "valV3 = modelV3.evaluate(val_Data, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = modelV3.evaluate(test_Data, verbose=2)\n",
    "print(model_eval)\n",
    "\n",
    "model_val = modelV3.evaluate(val_Data, steps=1, batch_size=val_size, verbose=2)\n",
    "print(model_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_labels = []\n",
    "numpy_images = []\n",
    "pred = []\n",
    "\n",
    "for images, labels in test_Data.take(-1):  # take all batches of dataset\n",
    "    numpy_images.extend(images.numpy())\n",
    "    numpy_labels.extend(labels.numpy())\n",
    "    pred.extend(modelV3.predict(images.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_misclassified(pred, numpy_labels, numpy_images, int((val_size - val_size*.9861 )/3 + 1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
